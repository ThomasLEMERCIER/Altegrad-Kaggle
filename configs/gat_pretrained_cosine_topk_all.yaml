# ==== Run name ==== #
name: gat_pretrained_cosine_all

# ==== Nlp model parameters ==== #
nlp_model_name: distilbert-base-uncased
custom_tokenizer: true
nlp_pretrained: true

# ==== GNN parameters ==== #
gnn_model_name: gat
gnn_num_layers: 6
gnn_hdim: 512
mlp_hdim: 512
gnn_dropout: 0.2
gnn_pretrained: true

# ==== Output parameters ==== #
nout: 768

# ==== Training parameters ==== #
nb_epochs: 80
batch_size: 440
lr: 2.e-5
weight_decay: 0.00002

# ==== Loss/Model options ==== #
norm_loss: False
avg_pool_nlp: False
top_k_loss: 440
top_k_scheduler:
  start: 440
  end: 180
optimizer: adamw

# ==== NLP checkpoint ==== #
nlp_checkpoint: checkpoint-7500

# === GNN checkpoint === #
gnn_checkpoint: pretraining_gat_2024-02-01_19-26-54/checkpoint_14.pt

# ==== Fine tuning ==== #
fine_tuning: False
checkpoint_name: null

# ==== Transform ==== #
lambda_aug: 0.
min_aug: 0
max_aug: 0

p_edge_pertubation: 0.
edge_pertubation: 0.

p_graph_sampling: 0.
graph_sampling: 0.

p_features_noise: 0.
features_noise: 0.

p_features_shuffling: 0.
features_shuffling: 0.

p_features_masking: 0.
features_masking: 0

p_k_hop_subgraph: 0

# ==== Scheduler ==== #
scheduler: warmup_cosine
warmup_epochs: 2
eta_min: 1.e-8
eta_max: 1.e-4

# === Data === #
use_unlabled: true
unlabeled_samples_share: 0.2