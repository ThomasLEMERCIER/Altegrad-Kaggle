# ==== Run name ==== #
name: baseline_norm

# ==== Nlp model parameters ==== #
nlp_model_name: distilbert-base-uncased
custom_tokenizer: False
nlp_pretrained: False

# ==== GNN parameters ==== #
gnn_model_name: gcn
gnn_num_layers: 3
gnn_hdim: 300
mlp_hdim: 300
gnn_dropout: 0.

# ==== Output parameters ==== #
nout: 768

# ==== Training parameters ==== #
nb_epochs: 10
batch_size: 64
lr: 2.e-5
weight_decay: 0.01

# ==== Loss/Model options ==== #
norm_loss: True
avg_pool_nlp: False

# ==== NLP checkpoint ==== #
nlp_checkpoint: null

# ==== Fine tuning ==== #
fine_tuning: False
checkpoint_name: null

# ==== Transform ==== #
lambda_aug: 0.
min_aug: 0
max_aug: 0

p_edge_pertubation: 0.
edge_pertubation: 0.

p_graph_sampling: 0.
graph_sampling: 0.

p_features_noise: 0.
features_noise: 0.

p_features_shuffling: 0.
features_shuffling: 0.

p_features_masking: 0.
features_masking: 0

# ==== Scheduler ==== #
scheduler: constant
eta_min: 2.e-5
